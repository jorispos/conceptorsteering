{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import pandas as pd\n",
    "from dataclasses import dataclass\n",
    "from transformer_lens import HookedTransformer\n",
    "from conceptor import compute_conceptor\n",
    "from datetime import datetime\n",
    "from conceptor_steering import load_steering_prompts, extract_activations\n",
    "from conceptor_steering import hooked_generate, generate_ave_hook, generate_ave_hook_addition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_rows', None)\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_colwidth', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class ExperimentConfig:\n",
    "    steering_prompts_path: str\n",
    "    prompt_to_steer: str\n",
    "    extraction_layer: int\n",
    "    seed: int\n",
    "    top_p: float = 0.3\n",
    "    temperature: float = 1.0\n",
    "    freq_penalty: float = 1.0\n",
    "    n_steered_examples: int = 5\n",
    "    model_name: str = 'gpt2-xl'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_extraction_layer = [12]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "configs = [\n",
    "    ExperimentConfig(\n",
    "        steering_prompts_path='./prompts/antonym.txt',\n",
    "        prompt_to_steer='maximum:',\n",
    "        extraction_layer=extraction_layer,\n",
    "        seed=0,\n",
    "        top_p=0.3,\n",
    "        temperature=1.0,\n",
    "        freq_penalty=1.0,\n",
    "        n_steered_examples=5,\n",
    "        model_name='EleutherAI/gpt-j-6B',\n",
    "    )\n",
    "    for extraction_layer in list_extraction_layer\n",
    "]\n",
    "config = configs[0]\n",
    "len(configs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n",
      ">> Loading model...\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(f\"Using device: {DEVICE}\")\n",
    "\n",
    "sampling_kwargs = dict(\n",
    "    temperature=config.temperature,\n",
    "    top_p=config.top_p,\n",
    "    freq_penalty=config.freq_penalty\n",
    ")\n",
    "\n",
    "# Load the model\n",
    "print(\">> Loading model...\")\n",
    "torch.set_grad_enabled(False)\n",
    "model = HookedTransformer.from_pretrained(config.model_name, device=DEVICE)\n",
    "model.eval();\n",
    "\n",
    "# Logging folder for batch experiments\n",
    "timestamp = datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "folder_path = os.path.join(\"resultsdata\", timestamp)\n",
    "os.makedirs(folder_path, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4b0500e3d09d4a2491138c023e8d15dc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "['maximum: 0.0; minimum: 0.0; step: 1.0\\n\\nThe maximum and minimum values are in decimal notation, and the step is in decimal point notation (e.g., 2.5 ).\\n\\nA value of zero',\n",
       " 'maximum:\\n\\n\"The maximum number of consecutive integers that can be represented in a given array.\"\\n\\n\\n\"The maximum number of consecutive integers that can be represented in a given array.\" minimum:\\n\\n\"The minimum number of consecutive integers that can be',\n",
       " 'maximum:\\n\\n* Required Field * Name of the User (required) Email Address (required) Password (required) * Required Field * Password Confirm Password * Your password must be at least 8 characters long.\\n\\n\\n* Please enter a valid email address',\n",
       " 'maximum: 100;\\n\\nmax-width: 200px;\\n\\nmax-height: 300px;\\n\\n\\n}\\n\\n\\n.side .md h1 { font-size: 18px; }\\n\\n\\n.side .md h2 { font',\n",
       " 'maximum:\\n\\n- 1.5 million players (in the game)\\n\\n- 1.5 million players (in the game) Maximum play time: 2 hours, 30 minutes per day, or up to 3 hours per week\\n\\n\\n2 hours,']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Generate and save unsteered results once\n",
    "unsteered_res = hooked_generate(model, [config.prompt_to_steer] * config.n_steered_examples, seed=config.seed, **sampling_kwargs)\n",
    "unsteered_str = model.to_string(unsteered_res[:, 1:])\n",
    "unsteered_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenized steering prompts:\n",
      "length: 16 : ['fl', 'awed', ':', 'perfect', ',', 'Ġorthodox', ':', 'un', 'orthodox', ',', 'Ġtrue', ':', 'false', ',', 'Ġdaily', ':'] | token at index -1: :\n",
      "length: 18 : ['dist', 'ribution', ':', 'con', 'cent', 'ration', ',', 'Ġvalid', ':', 'in', 'valid', ',', 'Ġexpand', ':', 'contract', ',', 'Ġpractical', ':'] | token at index -1: :\n",
      "length: 17 : ['priv', 'ilege', ':', 'dis', 'advant', 'age', ',', 'Ġmammoth', ':', 'tiny', ',', 'Ġunrelated', ':', 'related', ',', 'Ġovernight', ':'] | token at index -1: :\n",
      "length: 14 : ['other', ':', 'same', ',', 'Ġsquare', ':', 'circle', ',', 'Ġhollow', ':', 'solid', ',', 'Ġdifficult', ':'] | token at index -1: :\n",
      "length: 18 : ['lux', 'ury', ':', 'p', 'overty', ',', 'Ġstimulate', ':', 'in', 'hibit', ',', 'Ġproceed', ':', 'h', 'alt', ',', 'Ġfertile', ':'] | token at index -1: :\n",
      "length: 20 : ['em', 'pir', 'ical', ':', 'the', 'oret', 'ical', ',', 'Ġpretty', ':', 'ug', 'ly', ',', 'Ġclinical', ':', 'em', 'otional', ',', 'Ġlucky', ':'] | token at index -1: :\n",
      "length: 15 : ['tail', ':', 'head', ',', 'Ġprivacy', ':', 'public', 'ity', ',', 'Ġundergraduate', ':', 'graduate', ',', 'Ġencourage', ':'] | token at index -1: :\n",
      "length: 16 : ['in', 'secure', ':', 'secure', ',', 'Ġprofessional', ':', 'am', 'ateur', ',', 'Ġrapid', ':', 'slow', ',', 'Ġworthless', ':'] | token at index -1: :\n",
      "length: 17 : ['comp', 'ressed', ':', 'exp', 'anded', ',', 'Ġprose', ':', 'po', 'etry', ',', 'Ġwatch', ':', 'ignore', ',', 'Ġbeast', ':'] | token at index -1: :\n",
      "length: 17 : ['pro', ':', 'con', ',', 'Ġsilent', ':', 'no', 'isy', ',', 'Ġinflammatory', ':', 'anti', '-', 'inflammatory', ',', 'Ġremain', ':'] | token at index -1: :\n",
      "length: 17 : ['wrong', ':', 'right', ',', 'Ġwhisper', ':', 'sh', 'out', ',', 'Ġsentimental', ':', 'un', 'em', 'otional', ',', 'Ġfascism', ':'] | token at index -1: :\n",
      "length: 16 : ['super', ':', 'in', 'fer', 'ior', ',', 'Ġuncle', ':', 'aunt', ',', 'Ġexit', ':', 'entry', ',', 'Ġmatter', ':'] | token at index -1: :\n",
      "length: 17 : ['prom', 'inence', ':', 'ob', 'sc', 'urity', ',', 'Ġdemise', ':', 'birth', ',', 'Ġsecular', ':', 'religious', ',', 'Ġdeparture', ':'] | token at index -1: :\n",
      "length: 18 : ['bear', ':', 'de', 'er', ',', 'Ġfigure', ':', 'ground', ',', 'Ġconspicuous', ':', 'inc', 'ons', 'pic', 'uous', ',', 'Ġboom', ':'] | token at index -1: :\n",
      "length: 16 : ['cloud', 'y', ':', 'clear', ',', 'Ġunreasonable', ':', 'reasonable', ',', 'Ġforward', ':', 'back', 'ward', ',', 'Ġwide', ':'] | token at index -1: :\n",
      "length: 20 : ['rel', 'ent', ':', 'pers', 'ist', ',', 'Ġdisappoint', ':', 's', 'atisf', 'y', ',', 'Ġdurable', ':', 'fr', 'ag', 'ile', ',', 'Ġloaded', ':'] | token at index -1: :\n",
      "length: 14 : ['big', ':', 'small', ',', 'Ġavoid', ':', 'seek', ',', 'Ġinvent', ':', 'destroy', ',', 'Ġfalsehood', ':'] | token at index -1: :\n",
      "length: 17 : ['learn', ':', 'for', 'get', ',', 'Ġout', ':', 'in', ',', 'Ġnaked', ':', 'cl', 'ot', 'hed', ',', 'Ġsink', ':'] | token at index -1: :\n",
      "length: 17 : ['qu', 'ar', 'rel', ':', 'peace', ',', 'Ġantidote', ':', 'po', 'ison', ',', 'Ġgenuine', ':', 'fake', ',', 'Ġfurious', ':'] | token at index -1: :\n",
      "length: 16 : ['trust', ':', 'dist', 'rust', ',', 'Ġvague', ':', 'specific', ',', 'Ġgrandmother', ':', 'grand', 'father', ',', 'Ġignore', ':'] | token at index -1: :\n",
      "length: 15 : ['f', 'oul', ':', 'fair', ',', 'Ġsouth', ':', 'north', ',', 'Ġlaugh', ':', 'cry', ',', 'Ġindistinguishable', ':'] | token at index -1: :\n",
      "length: 15 : ['red', ':', 'blue', ',', 'Ġdisable', ':', 'enable', ',', 'Ġvisible', ':', 'in', 'visible', ',', 'Ġrestore', ':'] | token at index -1: :\n",
      "length: 16 : ['un', 'conscious', ':', 'conscious', ',', 'Ġprosecution', ':', 'defense', ',', 'Ġdaylight', ':', 'night', 'time', ',', 'Ġappearance', ':'] | token at index -1: :\n",
      "length: 17 : ['less', 'en', ':', 'incre', 'ase', ',', 'Ġwealthy', ':', 'poor', ',', 'Ġbisexual', ':', 'mon', 'osexual', ',', 'Ġanal', ':'] | token at index -1: :\n",
      "length: 20 : ['mer', 'it', ':', 'dem', 'er', 'it', ',', 'Ġauthorized', ':', 'una', 'uthor', 'ized', ',', 'Ġundesirable', ':', 'des', 'irable', ',', 'Ġunequal', ':'] | token at index -1: :\n",
      "length: 17 : ['in', 'flation', ':', 'def', 'lation', ',', 'Ġunfold', ':', 'fold', ',', 'Ġexpress', ':', 'supp', 'ress', ',', 'Ġnorthwestern', ':'] | token at index -1: :\n",
      "length: 17 : ['majority', ':', 'min', 'ority', ',', 'Ġapplied', ':', 'the', 'oret', 'ical', ',', 'Ġexplosive', ':', 'stable', ',', 'Ġspare', ':'] | token at index -1: :\n",
      "length: 18 : ['season', 'ed', ':', 'un', 'season', 'ed', ',', 'Ġdistribute', ':', 'collect', ',', 'Ġcelestial', ':', 'ter', 'restrial', ',', 'Ġrobust', ':'] | token at index -1: :\n",
      "length: 17 : ['d', 'ys', 'function', ':', 'function', ',', 'Ġknockout', ':', 'rev', 'ival', ',', 'Ġspiral', ':', 'straight', ',', 'Ġmainland', ':'] | token at index -1: :\n",
      "length: 18 : ['pen', 'alty', ':', 're', 'ward', ',', 'Ġcolored', ':', 'color', 'less', ',', 'Ġdefunct', ':', 'oper', 'ational', ',', 'Ġarithmetic', ':'] | token at index -1: :\n",
      "length: 21 : ['f', 'ault', 'y', ':', 'fl', 'aw', 'less', ',', 'Ġlegislative', ':', 'exec', 'utive', ',', 'Ġdistance', ':', 'pro', 'x', 'imity', ',', 'Ġcut', ':'] | token at index -1: :\n",
      "length: 18 : ['post', 'p', 'one', ':', 'ad', 'vance', ',', 'Ġrecord', ':', 'er', 'ase', ',', 'Ġdisregard', ':', 'consider', ',', 'Ġborrow', ':'] | token at index -1: :\n",
      "length: 17 : ['pre', 'vious', ':', 'next', ',', 'Ġreliable', ':', 'un', 'rel', 'iable', ',', 'Ġregress', ':', 'progress', ',', 'Ġexacerbate', ':'] | token at index -1: :\n",
      "length: 16 : ['danger', 'ous', ':', 'safe', ',', 'Ġblessed', ':', 'c', 'ursed', ',', 'Ġopposite', ':', 'similar', ',', 'Ġwest', ':'] | token at index -1: :\n",
      "length: 15 : ['un', 'employment', ':', 'employment', ',', 'Ġcow', ':', 'bull', ',', 'Ġfirst', ':', 'last', ',', 'Ġpossibility', ':'] | token at index -1: :\n",
      "length: 16 : ['fore', 'ground', ':', 'background', ',', 'Ġillustrious', ':', 'unknown', ',', 'Ġbarbaric', ':', 'civil', 'ized', ',', 'Ġlongtime', ':'] | token at index -1: :\n",
      "length: 18 : ['ind', 'ifferent', ':', 'pass', 'ion', 'ate', ',', 'Ġunlimited', ':', 'limited', ',', 'Ġbreach', ':', 'com', 'ply', ',', 'Ġfrontal', ':'] | token at index -1: :\n",
      "length: 15 : ['only', ':', 'many', ',', 'Ġlimited', ':', 'un', 'limited', ',', 'Ġdotted', ':', 'solid', ',', 'Ġcontingent', ':'] | token at index -1: :\n",
      "length: 15 : ['straight', ':', 'cur', 'ved', ',', 'Ġsummer', ':', 'winter', ',', 'Ġunlikely', ':', 'likely', ',', 'Ġold', ':'] | token at index -1: :\n",
      "length: 20 : ['earth', 'ly', ':', 'cel', 'estial', ',', 'Ġobservational', ':', 'the', 'oret', 'ical', ',', 'Ġcentrist', ':', 'ext', 'rem', 'ist', ',', 'Ġview', ':'] | token at index -1: :\n",
      "length: 16 : ['med', 'ial', ':', 'l', 'ateral', ',', 'Ġextraordinary', ':', 'ordinary', ',', 'Ġabolish', ':', 'establish', ',', 'Ġcry', ':'] | token at index -1: :\n",
      "length: 16 : ['undo', ':', 'do', ',', 'Ġcheer', ':', 'je', 'er', ',', 'Ġforce', ':', 'gent', 'leness', ',', 'Ġhooked', ':'] | token at index -1: :\n",
      "length: 16 : ['mist', 'aken', ':', 'correct', ',', 'Ġeldest', ':', 'young', 'est', ',', 'Ġfried', ':', 'raw', ',', 'Ġclassify', ':'] | token at index -1: :\n",
      "length: 19 : ['lo', 'osen', ':', 'tight', 'en', ',', 'Ġbroaden', ':', 'n', 'arrow', ',', 'Ġapproval', ':', 'dis', 'appro', 'val', ',', 'Ġeastern', ':'] | token at index -1: :\n",
      "length: 19 : ['p', 'olar', ':', 'equ', 'atorial', ',', 'Ġunbelievable', ':', 'bel', 'iev', 'able', ',', 'Ġtemporal', ':', 'et', 'ernal', ',', 'Ġlink', ':'] | token at index -1: :\n",
      "length: 19 : ['det', 'ain', ':', 'release', ',', 'Ġoutgoing', ':', 'int', 'ro', 'verted', ',', 'Ġbarren', ':', 'f', 'ert', 'ile', ',', 'Ġwhite', ':'] | token at index -1: :\n",
      "length: 18 : ['intuitive', ':', 'counter', 'intuitive', ',', 'Ġoutlaw', ':', 'law', '-', 'abiding', 'Ġcitizen', ',', 'Ġillegal', ':', 'legal', ',', 'Ġconcept', ':'] | token at index -1: :\n",
      "length: 18 : ['author', 'ize', ':', 'pro', 'hibit', ',', 'Ġintelligent', ':', 'un', 'int', 'elligent', ',', 'Ġundue', ':', 'due', ',', 'Ġcontrast', ':'] | token at index -1: :\n",
      "length: 18 : ['abs', 'ent', ':', 'present', ',', 'Ġconvergence', ':', 'd', 'iver', 'gence', ',', 'Ġshy', ':', 'out', 'going', ',', 'Ġmixed', ':'] | token at index -1: :\n",
      "length: 15 : ['head', ':', 'tail', ',', 'Ġcontemporary', ':', 'traditional', ',', 'Ġshameful', ':', 'hon', 'orable', ',', 'Ġsupreme', ':'] | token at index -1: :\n",
      "length: 19 : ['pro', 'ced', 'ural', ':', 'concept', 'ual', ',', 'Ġancestor', ':', 'desc', 'endant', ',', 'Ġsegregation', ':', 'integ', 'ration', ',', 'Ġgive', ':'] | token at index -1: :\n",
      "length: 16 : ['marg', 'inal', ':', 'central', ',', 'Ġbent', ':', 'straight', ',', 'Ġtomorrow', ':', 'yes', 'terday', ',', 'Ġlower', ':'] | token at index -1: :\n",
      "length: 19 : ['per', 'manent', ':', 'tem', 'porary', ',', 'Ġlend', ':', 'bor', 'row', ',', 'Ġcivil', ':', 'unc', 'ivil', 'ized', ',', 'Ġfictitious', ':'] | token at index -1: :\n",
      "length: 19 : ['d', 'orm', 'ant', ':', 'active', ',', 'Ġemployment', ':', 'un', 'employment', ',', 'Ġcomplexity', ':', 'sim', 'pl', 'icity', ',', 'Ġdefy', ':'] | token at index -1: :\n",
      "length: 19 : ['con', 'ventional', ':', 'un', 'con', 'ventional', ',', 'Ġexpected', ':', 'un', 'expected', ',', 'Ġautomated', ':', 'man', 'ual', ',', 'Ġbra', ':'] | token at index -1: :\n",
      "length: 16 : ['include', ':', 'ex', 'clude', ',', 'Ġpride', ':', 'hum', 'ility', ',', 'Ġoutcome', ':', 'input', ',', 'Ġobey', ':'] | token at index -1: :\n",
      "length: 14 : ['destroy', ':', 'create', ',', 'Ġdeduct', ':', 'add', ',', 'Ġlesbian', ':', 'straight', ',', 'Ġunlucky', ':'] | token at index -1: :\n",
      "length: 16 : ['special', 'ize', ':', 'general', 'ize', ',', 'Ġunable', ':', 'able', ',', 'Ġsuperhuman', ':', 'human', ',', 'Ġinverse', ':'] | token at index -1: :\n",
      "length: 15 : ['le', 'ast', ':', 'most', ',', 'Ġirrational', ':', 'rational', ',', 'Ġstale', ':', 'fresh', ',', 'Ġexclusive', ':'] | token at index -1: :\n",
      "length: 20 : ['st', 'urdy', ':', 'fr', 'ag', 'ile', ',', 'Ġliterary', ':', 'ill', 'iter', 'ate', ',', 'Ġregular', ':', 'ir', 'regular', ',', 'Ġalign', ':'] | token at index -1: :\n",
      "length: 19 : ['imp', 'ossible', ':', 'p', 'ossible', ',', 'Ġmartial', ':', 'civil', 'ian', ',', 'Ġfrustrated', ':', 's', 'atisf', 'ied', ',', 'Ġfake', ':'] | token at index -1: :\n",
      "length: 18 : ['ve', 'to', ':', 'appro', 've', ',', 'Ġapproximate', ':', 'ex', 'act', ',', 'Ġgradual', ':', 's', 'udden', ',', 'Ġimpractical', ':'] | token at index -1: :\n",
      "length: 19 : ['sm', 'ile', ':', 'f', 'rown', ',', 'Ġlegitimate', ':', 'il', 'leg', 'itimate', ',', 'Ġlimp', ':', 'st', 'iff', ',', 'Ġimprobable', ':'] | token at index -1: :\n",
      "length: 17 : ['comm', 'ence', ':', 'con', 'clude', ',', 'Ġput', ':', 'take', ',', 'Ġcover', ':', 'un', 'cover', ',', 'Ġlightweight', ':'] | token at index -1: :\n",
      "length: 19 : ['accept', 'ance', ':', 're', 'jection', ',', 'Ġpermission', ':', 'pro', 'hibition', ',', 'Ġmanned', ':', 'un', 'man', 'ned', ',', 'Ġnumerous', ':'] | token at index -1: :\n",
      "length: 17 : ['div', 'est', ':', 'invest', ',', 'Ġtropical', ':', 'p', 'olar', ',', 'Ġlikely', ':', 'un', 'likely', ',', 'Ġworsen', ':'] | token at index -1: :\n",
      "length: 17 : ['dec', 'ode', ':', 'en', 'code', ',', 'Ġexcessive', ':', 'ins', 'ufficient', ',', 'Ġdefend', ':', 'attack', ',', 'Ġsoutheastern', ':'] | token at index -1: :\n",
      "length: 21 : ['p', 'redict', 'ive', ':', 're', 'active', ',', 'Ġdivergence', ':', 'con', 'ver', 'gence', ',', 'Ġintensive', ':', 'rel', 'ax', 'ed', ',', 'Ġabandon', ':'] | token at index -1: :\n",
      "length: 15 : ['fore', ':', 'aft', ',', 'Ġcriticize', ':', 'p', 'raise', ',', 'Ġused', ':', 'new', ',', 'Ġchildbirth', ':'] | token at index -1: :\n",
      "length: 17 : ['h', 'ope', ':', 'des', 'pair', ',', 'Ġextant', ':', 'ext', 'inct', ',', 'Ġcomplex', ':', 'simple', ',', 'Ġtacit', ':'] | token at index -1: :\n",
      "length: 18 : ['night', 'time', ':', 'day', 'time', ',', 'Ġpremature', ':', 'm', 'ature', ',', 'Ġcomic', ':', 'tr', 'agic', ',', 'Ġpersonal', ':'] | token at index -1: :\n",
      "length: 17 : ['weak', ':', 'strong', ',', 'Ġinvisible', ':', 'visible', ',', 'Ġtaxable', ':', 'n', 'ont', 'ax', 'able', ',', 'Ġleading', ':'] | token at index -1: :\n",
      "length: 17 : ['lord', ':', 'serv', 'ant', ',', 'Ġadvance', ':', 'ret', 'reat', ',', 'Ġintense', ':', 'm', 'ild', ',', 'Ġdefinite', ':'] | token at index -1: :\n",
      "length: 18 : ['rect', 'angular', ':', 'circ', 'ular', ',', 'Ġmortal', ':', 'imm', 'ortal', ',', 'Ġinward', ':', 'out', 'ward', ',', 'Ġexcess', ':'] | token at index -1: :\n",
      "length: 17 : ['f', 'olly', ':', 'w', 'isdom', ',', 'Ġquestion', ':', 'answer', ',', 'Ġviolate', ':', 'com', 'ply', ',', 'Ġdigital', ':'] | token at index -1: :\n",
      "length: 19 : ['int', 'ens', 'ify', ':', 'dim', 'in', 'ish', ',', 'Ġlike', ':', 'dis', 'like', ',', 'Ġshort', ':', 'long', ',', 'Ġmean', ':'] | token at index -1: :\n",
      "length: 17 : ['jam', ':', 'j', 'elly', ',', 'Ġall', ':', 'none', ',', 'Ġdisinfect', ':', 'cont', 'am', 'inate', ',', 'Ġlongitudinal', ':'] | token at index -1: :\n",
      "length: 17 : ['red', 'und', 'ant', ':', 'essential', ',', 'Ġsimplify', ':', 'compl', 'icate', ',', 'Ġexternal', ':', 'internal', ',', 'Ġinteresting', ':'] | token at index -1: :\n",
      "length: 18 : ['mus', 'cular', ':', 'f', 'rail', ',', 'Ġstalk', ':', 'root', ',', 'Ġestablish', ':', 'd', 'ism', 'antle', ',', 'Ġdispleasure', ':'] | token at index -1: :\n",
      "length: 19 : ['app', 'ear', ':', 'dis', 'app', 'ear', ',', 'Ġconvenient', ':', 'in', 'con', 'venient', ',', 'Ġcease', ':', 'continue', ',', 'Ġinsignificant', ':'] | token at index -1: :\n",
      "length: 17 : ['bor', 'rower', ':', 'l', 'ender', ',', 'Ġimaginative', ':', 'pract', 'ical', ',', 'Ġslow', ':', 'fast', ',', 'Ġunited', ':'] | token at index -1: :\n",
      "length: 15 : ['park', ':', 'home', ',', 'Ġfloat', ':', 's', 'ink', ',', 'Ġsolitary', ':', 'social', ',', 'Ġfrog', ':'] | token at index -1: :\n",
      "length: 16 : ['re', 'ar', ':', 'front', ',', 'Ġnaughty', ':', 'nice', ',', 'Ġeccentric', ':', 'con', 'ventional', ',', 'Ġsinister', ':'] | token at index -1: :\n",
      "length: 15 : ['hit', ':', 'miss', ',', 'Ġtragedy', ':', 'com', 'edy', ',', 'Ġconservative', ':', 'liberal', ',', 'Ġsame', ':'] | token at index -1: :\n",
      "length: 18 : ['id', 'le', ':', 'bus', 'y', ',', 'Ġend', ':', 'begin', 'ning', ',', 'Ġproactive', ':', 're', 'active', ',', 'Ġcounterfeit', ':'] | token at index -1: :\n",
      "length: 18 : ['plate', 'au', ':', 'val', 'ley', ',', 'Ġcollect', ':', 'dis', 'perse', ',', 'Ġproblem', ':', 's', 'olution', ',', 'Ġunavailable', ':'] | token at index -1: :\n",
      "length: 19 : ['v', 'isc', 'eral', ':', 'ce', 're', 'bral', ',', 'Ġdramatic', ':', 'sub', 'tle', ',', 'Ġrisky', ':', 'safe', ',', 'Ġrevolutionary', ':'] | token at index -1: :\n",
      "length: 18 : ['central', ':', 'per', 'ipher', 'al', ',', 'Ġvaried', ':', 'un', 'iform', ',', 'Ġunmanned', ':', 'man', 'ned', ',', 'Ġdisadvantaged', ':'] | token at index -1: :\n",
      "length: 17 : ['inf', 'rared', ':', 'ult', 'raviolet', ',', 'Ġweakness', ':', 'strength', ',', 'Ġepidemic', ':', 'end', 'emic', ',', 'Ġslowing', ':'] | token at index -1: :\n",
      "length: 15 : ['bare', ':', 'covered', ',', 'Ġcontradict', ':', 'agree', ',', 'Ġdraw', ':', 'er', 'ase', ',', 'Ġsquat', ':'] | token at index -1: :\n",
      "length: 17 : ['gar', 'ner', ':', 'squ', 'ander', ',', 'Ġstrike', ':', 'sp', 'are', ',', 'Ġshow', ':', 'hide', ',', 'Ġloss', ':'] | token at index -1: :\n",
      "length: 17 : ['amb', 'iguous', ':', 'clear', ',', 'Ġleftist', ':', 'right', 'ist', ',', 'Ġupstream', ':', 'down', 'stream', ',', 'Ġinfinite', ':'] | token at index -1: :\n",
      "length: 19 : ['des', 'irable', ':', 'und', 'es', 'irable', ',', 'Ġpure', ':', 'imp', 'ure', ',', 'Ġopacity', ':', 'trans', 'parency', ',', 'Ġinland', ':'] | token at index -1: :\n",
      "length: 18 : ['harm', 'ful', ':', 'benef', 'icial', ',', 'Ġnotice', ':', 'ignore', ',', 'Ġbrave', ':', 'cow', 'ard', 'ly', ',', 'Ġongoing', ':'] | token at index -1: :\n",
      "length: 19 : ['advant', 'age', ':', 'dis', 'advant', 'age', ',', 'Ġcontiguous', ':', 'dis', 'j', 'ointed', ',', 'Ġmain', ':', 'secondary', ',', 'Ġpleasure', ':'] | token at index -1: :\n",
      "length: 19 : ['no', 'ise', ':', 'sil', 'ence', ',', 'Ġwise', ':', 'f', 'ool', 'ish', ',', 'Ġconvoluted', ':', 'straight', 'forward', ',', 'Ġrefuse', ':'] | token at index -1: :\n",
      "length: 17 : ['so', 'lder', ':', 'des', 'older', ',', 'Ġtransmitter', ':', 're', 'ceiver', ',', 'Ġpetty', ':', 'significant', ',', 'Ġnumerical', ':'] | token at index -1: :\n",
      "length: 17 : ['inst', 'ability', ':', 'st', 'ability', ',', 'Ġinstall', ':', 'un', 'install', ',', 'Ġsimplistic', ':', 'complex', ',', 'Ġlodge', ':'] | token at index -1: :\n",
      "length: 16 : ['employ', ':', 'un', 'employ', ',', 'Ġdecline', ':', 'incre', 'ase', ',', 'Ġtop', ':', 'bottom', ',', 'Ġcompatible', ':'] | token at index -1: :\n",
      "length: 21 : ['ge', 'ographic', ':', 'non', '-', 'ge', 'ographic', ',', 'Ġpreliminary', ':', 'final', ',', 'Ġfugitive', ':', 'law', '-', 'abiding', 'Ġcitizen', ',', 'Ġjoy', ':'] | token at index -1: :\n",
      "Encoded steering prompts:\n",
      "length: 2 : {'input_ids': [2704, 36825, 25, 25833, 11, 28299, 25, 403, 42539, 11, 2081, 25, 9562, 11, 4445, 25], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]} | token at index -1: Encoding(num_tokens=16, attributes=[ids, type_ids, tokens, offsets, attention_mask, special_tokens_mask, overflowing])\n",
      "length: 2 : {'input_ids': [17080, 3890, 25, 1102, 1087, 1358, 11, 4938, 25, 259, 12102, 11, 4292, 25, 28484, 11, 8472, 25], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]} | token at index -1: Encoding(num_tokens=18, attributes=[ids, type_ids, tokens, offsets, attention_mask, special_tokens_mask, overflowing])\n",
      "length: 2 : {'input_ids': [13776, 41866, 25, 6381, 13461, 496, 11, 44268, 25, 44152, 11, 19938, 25, 5363, 11, 13417, 25], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]} | token at index -1: Encoding(num_tokens=17, attributes=[ids, type_ids, tokens, offsets, attention_mask, special_tokens_mask, overflowing])\n",
      "length: 2 : {'input_ids': [847, 25, 31642, 11, 6616, 25, 45597, 11, 20596, 25, 39390, 11, 2408, 25], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]} | token at index -1: Encoding(num_tokens=14, attributes=[ids, type_ids, tokens, offsets, attention_mask, special_tokens_mask, overflowing])\n",
      "length: 2 : {'input_ids': [22564, 1601, 25, 79, 24085, 11, 26020, 25, 259, 26964, 11, 5120, 25, 71, 2501, 11, 31192, 25], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]} | token at index -1: Encoding(num_tokens=18, attributes=[ids, type_ids, tokens, offsets, attention_mask, special_tokens_mask, overflowing])\n",
      "length: 2 : {'input_ids': [368, 4063, 605, 25, 1169, 9997, 605, 11, 2495, 25, 1018, 306, 11, 8668, 25, 368, 25453, 11, 9670, 25], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]} | token at index -1: Encoding(num_tokens=20, attributes=[ids, type_ids, tokens, offsets, attention_mask, special_tokens_mask, overflowing])\n",
      "length: 2 : {'input_ids': [13199, 25, 2256, 11, 6782, 25, 11377, 414, 11, 22952, 25, 17680, 11, 7898, 25], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]} | token at index -1: Encoding(num_tokens=15, attributes=[ids, type_ids, tokens, offsets, attention_mask, special_tokens_mask, overflowing])\n",
      "length: 2 : {'input_ids': [259, 22390, 25, 22390, 11, 4708, 25, 321, 15093, 11, 5801, 25, 38246, 11, 28063, 25], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]} | token at index -1: Encoding(num_tokens=16, attributes=[ids, type_ids, tokens, offsets, attention_mask, special_tokens_mask, overflowing])\n",
      "length: 2 : {'input_ids': [5589, 2790, 25, 11201, 12249, 11, 27149, 25, 7501, 11973, 11, 2342, 25, 46430, 11, 13824, 25], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]} | token at index -1: Encoding(num_tokens=17, attributes=[ids, type_ids, tokens, offsets, attention_mask, special_tokens_mask, overflowing])\n",
      "length: 2 : {'input_ids': [1676, 25, 1102, 11, 10574, 25, 3919, 13560, 11, 23760, 25, 17096, 12, 32272, 11, 3520, 25], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]} | token at index -1: Encoding(num_tokens=17, attributes=[ids, type_ids, tokens, offsets, attention_mask, special_tokens_mask, overflowing])\n",
      "length: 2 : {'input_ids': [36460, 25, 3506, 11, 31992, 25, 1477, 448, 11, 46908, 25, 403, 368, 25453, 11, 31037, 25], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]} | token at index -1: Encoding(num_tokens=17, attributes=[ids, type_ids, tokens, offsets, attention_mask, special_tokens_mask, overflowing])\n",
      "length: 2 : {'input_ids': [16668, 25, 259, 2232, 1504, 11, 7711, 25, 12968, 11, 8420, 25, 13000, 11, 2300, 25], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]} | token at index -1: Encoding(num_tokens=16, attributes=[ids, type_ids, tokens, offsets, attention_mask, special_tokens_mask, overflowing])\n",
      "length: 2 : {'input_ids': [16963, 18386, 25, 672, 1416, 1684, 11, 25403, 25, 24280, 11, 14589, 25, 27626, 11, 12928, 25], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]} | token at index -1: Encoding(num_tokens=17, attributes=[ids, type_ids, tokens, offsets, attention_mask, special_tokens_mask, overflowing])\n",
      "length: 2 : {'input_ids': [33227, 25, 2934, 263, 11, 3785, 25, 2833, 11, 39089, 25, 1939, 684, 16564, 5623, 11, 14166, 25], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]} | token at index -1: Encoding(num_tokens=18, attributes=[ids, type_ids, tokens, offsets, attention_mask, special_tokens_mask, overflowing])\n",
      "length: 2 : {'input_ids': [17721, 88, 25, 20063, 11, 24673, 25, 42275, 11, 2651, 25, 1891, 904, 11, 3094, 25], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]} | token at index -1: Encoding(num_tokens=16, attributes=[ids, type_ids, tokens, offsets, attention_mask, special_tokens_mask, overflowing])\n",
      "length: 2 : {'input_ids': [2411, 298, 25, 19276, 396, 11, 6703, 25, 82, 17403, 88, 11, 20923, 25, 8310, 363, 576, 11, 9639, 25], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]} | token at index -1: Encoding(num_tokens=20, attributes=[ids, type_ids, tokens, offsets, attention_mask, special_tokens_mask, overflowing])\n",
      "length: 2 : {'input_ids': [14261, 25, 17470, 11, 3368, 25, 36163, 11, 8067, 25, 41659, 11, 37110, 25], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]} | token at index -1: Encoding(num_tokens=14, attributes=[ids, type_ids, tokens, offsets, attention_mask, special_tokens_mask, overflowing])\n",
      "length: 2 : {'input_ids': [35720, 25, 1640, 1136, 11, 503, 25, 259, 11, 12105, 25, 565, 313, 704, 11, 14595, 25], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]} | token at index -1: Encoding(num_tokens=17, attributes=[ids, type_ids, tokens, offsets, attention_mask, special_tokens_mask, overflowing])\n",
      "length: 2 : {'input_ids': [421, 283, 2411, 25, 22988, 11, 50131, 25, 7501, 1653, 11, 8768, 25, 30706, 11, 21799, 25], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]} | token at index -1: Encoding(num_tokens=17, attributes=[ids, type_ids, tokens, offsets, attention_mask, special_tokens_mask, overflowing])\n",
      "length: 2 : {'input_ids': [38087, 25, 17080, 11469, 11, 13443, 25, 11423, 11, 18410, 25, 23936, 11358, 11, 8856, 25], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]} | token at index -1: Encoding(num_tokens=16, attributes=[ids, type_ids, tokens, offsets, attention_mask, special_tokens_mask, overflowing])\n",
      "length: 2 : {'input_ids': [69, 2852, 25, 22043, 11, 5366, 25, 43588, 11, 6487, 25, 20470, 11, 43649, 25], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]} | token at index -1: Encoding(num_tokens=15, attributes=[ids, type_ids, tokens, offsets, attention_mask, special_tokens_mask, overflowing])\n",
      "length: 2 : {'input_ids': [445, 25, 17585, 11, 15560, 25, 21633, 11, 7424, 25, 259, 23504, 11, 11169, 25], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]} | token at index -1: Encoding(num_tokens=15, attributes=[ids, type_ids, tokens, offsets, attention_mask, special_tokens_mask, overflowing])\n",
      "length: 2 : {'input_ids': [403, 16796, 25, 16796, 11, 12580, 25, 19774, 11, 26010, 25, 3847, 2435, 11, 5585, 25], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]} | token at index -1: Encoding(num_tokens=16, attributes=[ids, type_ids, tokens, offsets, attention_mask, special_tokens_mask, overflowing])\n",
      "length: 2 : {'input_ids': [1203, 268, 25, 24988, 589, 11, 11574, 25, 36672, 11, 24249, 25, 2144, 8542, 11, 2037, 25], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]} | token at index -1: Encoding(num_tokens=17, attributes=[ids, type_ids, tokens, offsets, attention_mask, special_tokens_mask, overflowing])\n",
      "length: 2 : {'input_ids': [647, 270, 25, 9536, 263, 270, 11, 10435, 25, 9613, 1457, 1143, 11, 38117, 25, 8906, 13194, 11, 37334, 25], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]} | token at index -1: Encoding(num_tokens=20, attributes=[ids, type_ids, tokens, offsets, attention_mask, special_tokens_mask, overflowing])\n",
      "length: 2 : {'input_ids': [259, 33521, 25, 4299, 7592, 11, 16631, 25, 11379, 11, 4911, 25, 18608, 601, 11, 48164, 25], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]} | token at index -1: Encoding(num_tokens=17, attributes=[ids, type_ids, tokens, offsets, attention_mask, special_tokens_mask, overflowing])\n",
      "length: 2 : {'input_ids': [35839, 25, 1084, 29134, 11, 5625, 25, 1169, 9997, 605, 11, 13835, 25, 31284, 11, 13952, 25], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]} | token at index -1: Encoding(num_tokens=17, attributes=[ids, type_ids, tokens, offsets, attention_mask, special_tokens_mask, overflowing])\n",
      "length: 2 : {'input_ids': [6230, 276, 25, 403, 6230, 276, 11, 14983, 25, 33327, 11, 33258, 25, 353, 23522, 11, 12373, 25], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]} | token at index -1: Encoding(num_tokens=18, attributes=[ids, type_ids, tokens, offsets, attention_mask, special_tokens_mask, overflowing])\n",
      "length: 2 : {'input_ids': [67, 893, 8818, 25, 8818, 11, 35825, 25, 18218, 2473, 11, 23642, 25, 42729, 11, 22779, 25], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]} | token at index -1: Encoding(num_tokens=17, attributes=[ids, type_ids, tokens, offsets, attention_mask, special_tokens_mask, overflowing])\n",
      "length: 2 : {'input_ids': [3617, 6017, 25, 260, 904, 11, 16396, 25, 8043, 1203, 11, 49119, 25, 3575, 864, 11, 34768, 25], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]} | token at index -1: Encoding(num_tokens=18, attributes=[ids, type_ids, tokens, offsets, attention_mask, special_tokens_mask, overflowing])\n",
      "length: 2 : {'input_ids': [69, 1721, 88, 25, 2704, 707, 1203, 11, 10828, 25, 18558, 8827, 11, 5253, 25, 1676, 87, 18853, 11, 2005, 25], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]} | token at index -1: Encoding(num_tokens=21, attributes=[ids, type_ids, tokens, offsets, attention_mask, special_tokens_mask, overflowing])\n",
      "length: 2 : {'input_ids': [7353, 79, 505, 25, 324, 19259, 11, 1700, 25, 263, 589, 11, 25070, 25, 44353, 11, 8804, 25], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]} | token at index -1: Encoding(num_tokens=18, attributes=[ids, type_ids, tokens, offsets, attention_mask, special_tokens_mask, overflowing])\n",
      "length: 2 : {'input_ids': [3866, 1442, 25, 19545, 11, 9314, 25, 403, 2411, 3379, 11, 50252, 25, 33723, 11, 49522, 25], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]} | token at index -1: Encoding(num_tokens=17, attributes=[ids, type_ids, tokens, offsets, attention_mask, special_tokens_mask, overflowing])\n",
      "length: 2 : {'input_ids': [38537, 516, 25, 21230, 11, 18259, 25, 66, 17539, 11, 6697, 25, 38610, 11, 7421, 25], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]} | token at index -1: Encoding(num_tokens=16, attributes=[ids, type_ids, tokens, offsets, attention_mask, special_tokens_mask, overflowing])\n",
      "length: 2 : {'input_ids': [403, 28812, 25, 28812, 11, 9875, 25, 16308, 11, 717, 25, 12957, 11, 5885, 25], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]} | token at index -1: Encoding(num_tokens=15, attributes=[ids, type_ids, tokens, offsets, attention_mask, special_tokens_mask, overflowing])\n",
      "length: 2 : {'input_ids': [754, 2833, 25, 25249, 11, 47887, 25, 34680, 11, 48176, 25, 37636, 1143, 11, 15076, 25], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]} | token at index -1: Encoding(num_tokens=16, attributes=[ids, type_ids, tokens, offsets, attention_mask, special_tokens_mask, overflowing])\n",
      "length: 2 : {'input_ids': [521, 17125, 25, 6603, 295, 378, 11, 15822, 25, 10698, 11, 13694, 25, 785, 2145, 11, 30424, 25], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]} | token at index -1: Encoding(num_tokens=18, attributes=[ids, type_ids, tokens, offsets, attention_mask, special_tokens_mask, overflowing])\n",
      "length: 2 : {'input_ids': [8807, 25, 21834, 11, 3614, 25, 403, 10698, 11, 38745, 25, 39390, 11, 25477, 25], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]} | token at index -1: Encoding(num_tokens=15, attributes=[ids, type_ids, tokens, offsets, attention_mask, special_tokens_mask, overflowing])\n",
      "length: 2 : {'input_ids': [42729, 25, 22019, 1079, 11, 3931, 25, 40078, 11, 7485, 25, 40798, 11, 1468, 25], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]} | token at index -1: Encoding(num_tokens=15, attributes=[ids, type_ids, tokens, offsets, attention_mask, special_tokens_mask, overflowing])\n",
      "length: 2 : {'input_ids': [16442, 306, 25, 5276, 21711, 11, 40118, 25, 1169, 9997, 605, 11, 47609, 25, 2302, 2787, 396, 11, 1570, 25], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]} | token at index -1: Encoding(num_tokens=20, attributes=[ids, type_ids, tokens, offsets, attention_mask, special_tokens_mask, overflowing])\n",
      "length: 2 : {'input_ids': [1150, 498, 25, 75, 10534, 11, 11359, 25, 35947, 11, 35531, 25, 40037, 11, 3960, 25], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]} | token at index -1: Encoding(num_tokens=16, attributes=[ids, type_ids, tokens, offsets, attention_mask, special_tokens_mask, overflowing])\n",
      "length: 2 : {'input_ids': [41204, 25, 4598, 11, 14042, 25, 18015, 263, 11, 2700, 25, 6783, 48795, 11, 23373, 25], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]} | token at index -1: Encoding(num_tokens=16, attributes=[ids, type_ids, tokens, offsets, attention_mask, special_tokens_mask, overflowing])\n",
      "length: 2 : {'input_ids': [37980, 1685, 25, 30283, 11, 34331, 25, 35465, 395, 11, 23018, 25, 1831, 11, 36509, 25], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]} | token at index -1: Encoding(num_tokens=16, attributes=[ids, type_ids, tokens, offsets, attention_mask, special_tokens_mask, overflowing])\n",
      "length: 2 : {'input_ids': [5439, 5233, 25, 33464, 268, 11, 44870, 25, 77, 6018, 11, 7546, 25, 6381, 21064, 2100, 11, 10183, 25], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]} | token at index -1: Encoding(num_tokens=19, attributes=[ids, type_ids, tokens, offsets, attention_mask, special_tokens_mask, overflowing])\n",
      "length: 2 : {'input_ids': [79, 6192, 25, 4853, 21592, 11, 24479, 25, 6667, 11203, 540, 11, 21964, 25, 316, 35220, 11, 2792, 25], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]} | token at index -1: Encoding(num_tokens=19, attributes=[ids, type_ids, tokens, offsets, attention_mask, special_tokens_mask, overflowing])\n",
      "length: 2 : {'input_ids': [15255, 391, 25, 20979, 11, 28181, 25, 600, 305, 13658, 11, 39497, 25, 69, 861, 576, 11, 2330, 25], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]} | token at index -1: Encoding(num_tokens=19, attributes=[ids, type_ids, tokens, offsets, attention_mask, special_tokens_mask, overflowing])\n",
      "length: 2 : {'input_ids': [42105, 25, 24588, 42105, 11, 23716, 25, 6270, 12, 43056, 9511, 11, 5293, 25, 18011, 11, 3721, 25], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]} | token at index -1: Encoding(num_tokens=18, attributes=[ids, type_ids, tokens, offsets, attention_mask, special_tokens_mask, overflowing])\n",
      "length: 2 : {'input_ids': [9800, 1096, 25, 1676, 26964, 11, 12661, 25, 403, 600, 32940, 11, 38826, 25, 23301, 11, 6273, 25], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]} | token at index -1: Encoding(num_tokens=18, attributes=[ids, type_ids, tokens, offsets, attention_mask, special_tokens_mask, overflowing])\n",
      "length: 2 : {'input_ids': [8937, 298, 25, 25579, 11, 40826, 25, 67, 1428, 12745, 11, 15800, 25, 448, 5146, 11, 7668, 25], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]} | token at index -1: Encoding(num_tokens=18, attributes=[ids, type_ids, tokens, offsets, attention_mask, special_tokens_mask, overflowing])\n",
      "length: 2 : {'input_ids': [2256, 25, 13199, 11, 11811, 25, 36380, 11, 34078, 25, 24130, 10475, 11, 17700, 25], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]} | token at index -1: Encoding(num_tokens=15, attributes=[ids, type_ids, tokens, offsets, attention_mask, special_tokens_mask, overflowing])\n",
      "length: 2 : {'input_ids': [1676, 771, 1523, 25, 43169, 723, 11, 31836, 25, 20147, 23048, 11, 26718, 25, 18908, 1358, 11, 1577, 25], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]} | token at index -1: Encoding(num_tokens=19, attributes=[ids, type_ids, tokens, offsets, attention_mask, special_tokens_mask, overflowing])\n",
      "length: 2 : {'input_ids': [30887, 1292, 25, 31463, 11, 17157, 25, 42729, 11, 9439, 25, 8505, 6432, 11, 2793, 25], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]} | token at index -1: Encoding(num_tokens=16, attributes=[ids, type_ids, tokens, offsets, attention_mask, special_tokens_mask, overflowing])\n",
      "length: 2 : {'input_ids': [525, 44172, 25, 11498, 5551, 11, 22096, 25, 2865, 808, 11, 3026, 25, 19524, 2464, 1143, 11, 46718, 25], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]} | token at index -1: Encoding(num_tokens=19, attributes=[ids, type_ids, tokens, offsets, attention_mask, special_tokens_mask, overflowing])\n",
      "length: 2 : {'input_ids': [67, 579, 415, 25, 5275, 11, 7184, 25, 403, 28812, 11, 13357, 25, 14323, 489, 8467, 11, 37462, 25], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]} | token at index -1: Encoding(num_tokens=19, attributes=[ids, type_ids, tokens, offsets, attention_mask, special_tokens_mask, overflowing])\n",
      "length: 2 : {'input_ids': [1102, 20405, 25, 403, 1102, 20405, 11, 2938, 25, 403, 40319, 11, 16359, 25, 805, 723, 11, 8290, 25], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]} | token at index -1: Encoding(num_tokens=19, attributes=[ids, type_ids, tokens, offsets, attention_mask, special_tokens_mask, overflowing])\n",
      "length: 2 : {'input_ids': [17256, 25, 1069, 9152, 11, 11293, 25, 17047, 879, 11, 8055, 25, 15414, 11, 22389, 25], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]} | token at index -1: Encoding(num_tokens=16, attributes=[ids, type_ids, tokens, offsets, attention_mask, special_tokens_mask, overflowing])\n",
      "length: 2 : {'input_ids': [41659, 25, 17953, 11, 18777, 25, 2860, 11, 17834, 25, 42729, 11, 39411, 25], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]} | token at index -1: Encoding(num_tokens=14, attributes=[ids, type_ids, tokens, offsets, attention_mask, special_tokens_mask, overflowing])\n",
      "length: 2 : {'input_ids': [20887, 1096, 25, 24622, 1096, 11, 5906, 25, 540, 11, 47262, 25, 10734, 11, 34062, 25], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]} | token at index -1: Encoding(num_tokens=16, attributes=[ids, type_ids, tokens, offsets, attention_mask, special_tokens_mask, overflowing])\n",
      "length: 2 : {'input_ids': [293, 459, 25, 1712, 11, 25086, 25, 20310, 11, 39985, 25, 48797, 11, 8568, 25], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]} | token at index -1: Encoding(num_tokens=15, attributes=[ids, type_ids, tokens, offsets, attention_mask, special_tokens_mask, overflowing])\n",
      "length: 2 : {'input_ids': [301, 22876, 25, 8310, 363, 576, 11, 16716, 25, 359, 2676, 378, 11, 3218, 25, 343, 16338, 11, 10548, 25], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]} | token at index -1: Encoding(num_tokens=20, attributes=[ids, type_ids, tokens, offsets, attention_mask, special_tokens_mask, overflowing])\n",
      "length: 2 : {'input_ids': [11011, 4733, 25, 79, 4733, 11, 15618, 25, 37636, 666, 11, 14718, 25, 82, 17403, 798, 11, 8390, 25], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]} | token at index -1: Encoding(num_tokens=19, attributes=[ids, type_ids, tokens, offsets, attention_mask, special_tokens_mask, overflowing])\n",
      "length: 2 : {'input_ids': [303, 1462, 25, 21064, 303, 11, 27665, 25, 1069, 529, 11, 24972, 25, 82, 16557, 11, 43994, 25], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]} | token at index -1: Encoding(num_tokens=18, attributes=[ids, type_ids, tokens, offsets, attention_mask, special_tokens_mask, overflowing])\n",
      "length: 2 : {'input_ids': [5796, 576, 25, 69, 2053, 11, 9829, 25, 346, 1455, 30233, 11, 42102, 25, 301, 733, 11, 40494, 25], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]} | token at index -1: Encoding(num_tokens=19, attributes=[ids, type_ids, tokens, offsets, attention_mask, special_tokens_mask, overflowing])\n",
      "length: 2 : {'input_ids': [9503, 594, 25, 1102, 9152, 11, 1234, 25, 20657, 11, 3002, 25, 403, 9631, 11, 18700, 25], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]} | token at index -1: Encoding(num_tokens=17, attributes=[ids, type_ids, tokens, offsets, attention_mask, special_tokens_mask, overflowing])\n",
      "length: 2 : {'input_ids': [13635, 590, 25, 260, 29192, 11, 7170, 25, 1676, 24108, 11, 34737, 25, 403, 805, 2817, 11, 6409, 25], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]} | token at index -1: Encoding(num_tokens=19, attributes=[ids, type_ids, tokens, offsets, attention_mask, special_tokens_mask, overflowing])\n",
      "length: 2 : {'input_ids': [7146, 395, 25, 24859, 11, 19690, 25, 79, 6192, 11, 1884, 25, 403, 40798, 11, 47058, 25], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]} | token at index -1: Encoding(num_tokens=17, attributes=[ids, type_ids, tokens, offsets, attention_mask, special_tokens_mask, overflowing])\n",
      "length: 2 : {'input_ids': [12501, 1098, 25, 268, 8189, 11, 13181, 25, 1040, 15267, 11, 4404, 25, 20358, 11, 35618, 25], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]} | token at index -1: Encoding(num_tokens=17, attributes=[ids, type_ids, tokens, offsets, attention_mask, special_tokens_mask, overflowing])\n",
      "length: 2 : {'input_ids': [79, 17407, 425, 25, 260, 5275, 11, 43366, 25, 1102, 332, 12745, 11, 18590, 25, 2411, 897, 276, 11, 6871, 25], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]} | token at index -1: Encoding(num_tokens=21, attributes=[ids, type_ids, tokens, offsets, attention_mask, special_tokens_mask, overflowing])\n",
      "length: 2 : {'input_ids': [754, 25, 14940, 11, 24628, 25, 79, 40225, 11, 973, 25, 3605, 11, 43886, 25], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]} | token at index -1: Encoding(num_tokens=15, attributes=[ids, type_ids, tokens, offsets, attention_mask, special_tokens_mask, overflowing])\n",
      "length: 2 : {'input_ids': [71, 3008, 25, 8906, 24874, 11, 47862, 25, 2302, 4612, 11, 3716, 25, 36439, 11, 40787, 25], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]} | token at index -1: Encoding(num_tokens=17, attributes=[ids, type_ids, tokens, offsets, attention_mask, special_tokens_mask, overflowing])\n",
      "length: 2 : {'input_ids': [3847, 2435, 25, 820, 2435, 11, 19905, 25, 76, 1300, 11, 9048, 25, 2213, 9083, 11, 2614, 25], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]} | token at index -1: Encoding(num_tokens=18, attributes=[ids, type_ids, tokens, offsets, attention_mask, special_tokens_mask, overflowing])\n",
      "length: 2 : {'input_ids': [38695, 25, 11576, 11, 14836, 25, 23504, 11, 25069, 25, 77, 756, 897, 540, 11, 3756, 25], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]} | token at index -1: Encoding(num_tokens=17, attributes=[ids, type_ids, tokens, offsets, attention_mask, special_tokens_mask, overflowing])\n",
      "length: 2 : {'input_ids': [10572, 25, 3168, 415, 11, 5963, 25, 1186, 630, 11, 8157, 25, 76, 688, 11, 21892, 25], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]} | token at index -1: Encoding(num_tokens=17, attributes=[ids, type_ids, tokens, offsets, attention_mask, special_tokens_mask, overflowing])\n",
      "length: 2 : {'input_ids': [2554, 21413, 25, 21170, 934, 11, 22122, 25, 8608, 16906, 11, 29879, 25, 448, 904, 11, 6992, 25], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]} | token at index -1: Encoding(num_tokens=18, attributes=[ids, type_ids, tokens, offsets, attention_mask, special_tokens_mask, overflowing])\n",
      "length: 2 : {'input_ids': [69, 5098, 25, 86, 9350, 11, 1808, 25, 41484, 11, 16967, 25, 785, 2145, 11, 4875, 25], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]} | token at index -1: Encoding(num_tokens=17, attributes=[ids, type_ids, tokens, offsets, attention_mask, special_tokens_mask, overflowing])\n",
      "length: 2 : {'input_ids': [600, 641, 1958, 25, 27740, 259, 680, 11, 588, 25, 6381, 2339, 11, 1790, 25, 6511, 11, 1612, 25], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]} | token at index -1: Encoding(num_tokens=19, attributes=[ids, type_ids, tokens, offsets, attention_mask, special_tokens_mask, overflowing])\n",
      "length: 2 : {'input_ids': [39159, 25, 73, 6148, 11, 477, 25, 23108, 11, 48511, 25, 3642, 321, 4559, 11, 36211, 25], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]} | token at index -1: Encoding(num_tokens=17, attributes=[ids, type_ids, tokens, offsets, attention_mask, special_tokens_mask, overflowing])\n",
      "length: 2 : {'input_ids': [445, 917, 415, 25, 31195, 11, 30276, 25, 23855, 5344, 11, 7097, 25, 32538, 11, 3499, 25], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]} | token at index -1: Encoding(num_tokens=17, attributes=[ids, type_ids, tokens, offsets, attention_mask, special_tokens_mask, overflowing])\n",
      "length: 2 : {'input_ids': [14664, 10440, 25, 69, 30224, 11, 31297, 25, 15763, 11, 4474, 25, 67, 1042, 16941, 11, 47313, 25], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]} | token at index -1: Encoding(num_tokens=18, attributes=[ids, type_ids, tokens, offsets, attention_mask, special_tokens_mask, overflowing])\n",
      "length: 2 : {'input_ids': [1324, 451, 25, 6381, 1324, 451, 11, 11282, 25, 259, 1102, 48109, 11, 13468, 25, 43043, 11, 32081, 25], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]} | token at index -1: Encoding(num_tokens=19, attributes=[ids, type_ids, tokens, offsets, attention_mask, special_tokens_mask, overflowing])\n",
      "length: 2 : {'input_ids': [2865, 46992, 25, 75, 2194, 11, 41138, 25, 29152, 605, 11, 3105, 25, 7217, 11, 16503, 25], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]} | token at index -1: Encoding(num_tokens=17, attributes=[ids, type_ids, tokens, offsets, attention_mask, special_tokens_mask, overflowing])\n",
      "length: 2 : {'input_ids': [20928, 25, 11195, 11, 12178, 25, 82, 676, 11, 25565, 25, 14557, 11, 21264, 25], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]} | token at index -1: Encoding(num_tokens=15, attributes=[ids, type_ids, tokens, offsets, attention_mask, special_tokens_mask, overflowing])\n",
      "length: 2 : {'input_ids': [260, 283, 25, 8534, 11, 45128, 25, 44460, 11, 29303, 25, 1102, 20405, 11, 26592, 25], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]} | token at index -1: Encoding(num_tokens=16, attributes=[ids, type_ids, tokens, offsets, attention_mask, special_tokens_mask, overflowing])\n",
      "length: 2 : {'input_ids': [17945, 25, 3927, 11, 13574, 25, 785, 4716, 11, 5940, 25, 35739, 11, 976, 25], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]} | token at index -1: Encoding(num_tokens=15, attributes=[ids, type_ids, tokens, offsets, attention_mask, special_tokens_mask, overflowing])\n",
      "length: 2 : {'input_ids': [312, 293, 25, 10885, 88, 11, 886, 25, 27471, 768, 11, 33943, 25, 260, 5275, 11, 36497, 25], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]} | token at index -1: Encoding(num_tokens=18, attributes=[ids, type_ids, tokens, offsets, attention_mask, special_tokens_mask, overflowing])\n",
      "length: 2 : {'input_ids': [6816, 559, 25, 2100, 1636, 11, 2824, 25, 6381, 38696, 11, 1917, 25, 82, 2122, 11, 23485, 25], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]} | token at index -1: Encoding(num_tokens=18, attributes=[ids, type_ids, tokens, offsets, attention_mask, special_tokens_mask, overflowing])\n",
      "length: 2 : {'input_ids': [85, 2304, 1691, 25, 344, 260, 24427, 11, 10092, 25, 7266, 7100, 11, 17564, 25, 21230, 11, 12253, 25], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]} | token at index -1: Encoding(num_tokens=19, attributes=[ids, type_ids, tokens, offsets, attention_mask, special_tokens_mask, overflowing])\n",
      "length: 2 : {'input_ids': [31463, 25, 525, 10803, 282, 11, 15641, 25, 403, 6933, 11, 35272, 25, 805, 2817, 11, 36327, 25], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]} | token at index -1: Encoding(num_tokens=18, attributes=[ids, type_ids, tokens, offsets, attention_mask, special_tokens_mask, overflowing])\n",
      "length: 2 : {'input_ids': [10745, 25122, 25, 586, 44223, 11, 10453, 25, 41402, 11, 18195, 25, 437, 5314, 11, 21605, 25], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]} | token at index -1: Encoding(num_tokens=17, attributes=[ids, type_ids, tokens, offsets, attention_mask, special_tokens_mask, overflowing])\n",
      "length: 2 : {'input_ids': [49382, 25, 32111, 11, 18372, 25, 49221, 11, 3197, 25, 263, 589, 11, 22713, 25], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]} | token at index -1: Encoding(num_tokens=15, attributes=[ids, type_ids, tokens, offsets, attention_mask, special_tokens_mask, overflowing])\n",
      "length: 2 : {'input_ids': [4563, 1008, 25, 16485, 4066, 11, 5587, 25, 2777, 533, 11, 905, 25, 24717, 11, 2994, 25], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]} | token at index -1: Encoding(num_tokens=17, attributes=[ids, type_ids, tokens, offsets, attention_mask, special_tokens_mask, overflowing])\n",
      "length: 2 : {'input_ids': [4131, 29709, 25, 20063, 11, 28318, 25, 3506, 396, 11, 28717, 25, 2902, 5532, 11, 15541, 25], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]} | token at index -1: Encoding(num_tokens=17, attributes=[ids, type_ids, tokens, offsets, attention_mask, special_tokens_mask, overflowing])\n",
      "length: 2 : {'input_ids': [8906, 13194, 25, 917, 274, 13194, 11, 5899, 25, 11011, 495, 11, 45912, 25, 7645, 11944, 11, 37874, 25], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]} | token at index -1: Encoding(num_tokens=19, attributes=[ids, type_ids, tokens, offsets, attention_mask, special_tokens_mask, overflowing])\n",
      "length: 2 : {'input_ids': [29155, 913, 25, 36934, 6652, 11, 4003, 25, 46430, 11, 14802, 25, 8232, 446, 306, 11, 7044, 25], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]} | token at index -1: Encoding(num_tokens=18, attributes=[ids, type_ids, tokens, offsets, attention_mask, special_tokens_mask, overflowing])\n",
      "length: 2 : {'input_ids': [13461, 496, 25, 6381, 13461, 496, 11, 48627, 25, 6381, 73, 20909, 11, 1388, 25, 38238, 11, 9476, 25], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]} | token at index -1: Encoding(num_tokens=19, attributes=[ids, type_ids, tokens, offsets, attention_mask, special_tokens_mask, overflowing])\n",
      "length: 2 : {'input_ids': [3919, 786, 25, 18217, 594, 11, 10787, 25, 69, 970, 680, 11, 47370, 25, 42729, 11813, 11, 11148, 25], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]} | token at index -1: Encoding(num_tokens=19, attributes=[ids, type_ids, tokens, offsets, attention_mask, special_tokens_mask, overflowing])\n",
      "length: 2 : {'input_ids': [568, 6499, 25, 8906, 19892, 11, 35099, 25, 260, 39729, 11, 25229, 25, 36591, 11, 29052, 25], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]} | token at index -1: Encoding(num_tokens=17, attributes=[ids, type_ids, tokens, offsets, attention_mask, special_tokens_mask, overflowing])\n",
      "length: 2 : {'input_ids': [8625, 1799, 25, 301, 1799, 11, 2721, 25, 403, 17350, 11, 35010, 25, 41887, 11, 35362, 25], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]} | token at index -1: Encoding(num_tokens=17, attributes=[ids, type_ids, tokens, offsets, attention_mask, special_tokens_mask, overflowing])\n",
      "length: 2 : {'input_ids': [7033, 25, 403, 7033, 11, 7794, 25, 24988, 589, 11, 1353, 25, 22487, 11, 11670, 25], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]} | token at index -1: Encoding(num_tokens=16, attributes=[ids, type_ids, tokens, offsets, attention_mask, special_tokens_mask, overflowing])\n",
      "length: 2 : {'input_ids': [469, 6826, 25, 13159, 12, 469, 6826, 11, 15223, 25, 20311, 11, 43799, 25, 6270, 12, 43056, 9511, 11, 8716, 25], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]} | token at index -1: Encoding(num_tokens=21, attributes=[ids, type_ids, tokens, offsets, attention_mask, special_tokens_mask, overflowing])\n"
     ]
    }
   ],
   "source": [
    "# Get the strings of all steering prompts\n",
    "steering_prompts = load_steering_prompts(model, config.steering_prompts_path, add_padding=False) # (n_prompts) list of strings\n",
    "\n",
    "# Tokenized steering prompts\n",
    "print(\"Tokenized steering prompts:\")\n",
    "tokenized_prompts = [model.tokenizer.tokenize(prompt, add_special_tokens=True) for prompt in steering_prompts]\n",
    "for prompt in tokenized_prompts:\n",
    "    print(\"length: \" + str(len(prompt)) + \" : \" + str(prompt) + \" | token at index -1: \" + str(prompt[-1]))\n",
    "\n",
    "# Encoded steering prompts\n",
    "print(\"Encoded steering prompts:\")\n",
    "tokenized_prompts = [model.tokenizer.encode_plus(prompt, add_special_tokens=True) for prompt in steering_prompts]\n",
    "for prompt in tokenized_prompts:\n",
    "    print(\"length: \" + str(len(prompt)) + \" : \" + str(prompt) + \" | token at index -1: \" + str(prompt[-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "layer=12\n",
      "\n",
      "Starting to extract activations for 100 prompts at layer 12\n",
      "avg_activations shape: torch.Size([1, 1600])\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "57efac5f16994e429b633d5b29d1878b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "changing torch.Size([5, 3, 1600]) from token_index: 2 with steering_vector: torch.Size([1, 1600])\n",
      "\n",
      "layer=24\n",
      "\n",
      "Starting to extract activations for 100 prompts at layer 24\n",
      "avg_activations shape: torch.Size([1, 1600])\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "65bbf305501e46c3aba8d89e02e8c2cc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "changing torch.Size([5, 3, 1600]) from token_index: 2 with steering_vector: torch.Size([1, 1600])\n"
     ]
    }
   ],
   "source": [
    "# store results\n",
    "results = [\n",
    "    {\n",
    "        \"steered\": False,\n",
    "        \"input\": config.prompt_to_steer,\n",
    "        \"output\": unsteered_str[idx],\n",
    "    }\n",
    "    for idx in range(config.n_steered_examples)\n",
    "]\n",
    "\n",
    "for config in configs:\n",
    "    print(f\"\\nlayer={config.extraction_layer}\\n\")\n",
    "\n",
    "    # Calculate steering vector\n",
    "    activations = extract_activations(model, steering_prompts, config.extraction_layer, device=DEVICE, token_indices=[-2])\n",
    "    avg_activations = torch.mean(activations, dim=0) # (num_token_indices, num_activations)\n",
    "    print(\"avg_activations shape: \" + str(avg_activations.shape))\n",
    "\n",
    "    # Add onto the model during forward passes\n",
    "    ave_hook = generate_ave_hook_addition(steering_vector=avg_activations, token_index=-2)\n",
    "    editing_hooks = [(f\"blocks.{config.extraction_layer}.hook_resid_pre\", ave_hook)]\n",
    "\n",
    "    # Generate text using the conceptor-steered model\n",
    "    steered_res = hooked_generate(model, [config.prompt_to_steer] * config.n_steered_examples, fwd_hooks=editing_hooks, seed=config.seed, **sampling_kwargs)\n",
    "    outputs = model.to_string(steered_res[:, 1:])\n",
    "\n",
    "    # save results to file\n",
    "    for output in outputs:\n",
    "        results.append({\n",
    "            \"steered\": True,\n",
    "            \"input\": config.prompt_to_steer,\n",
    "            \"output\": output,\n",
    "        })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>steered</th>\n",
       "      <th>layer</th>\n",
       "      <th>input</th>\n",
       "      <th>output</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>False</td>\n",
       "      <td>6</td>\n",
       "      <td>maximum:</td>\n",
       "      <td>maximum: 0.0; minimum: 0.0; step: 1.0\\n\\nThe maximum and minimum values are in decimal notation, and the step is in ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>False</td>\n",
       "      <td>6</td>\n",
       "      <td>maximum:</td>\n",
       "      <td>maximum:\\n\\n\"The maximum number of consecutive integers that can be represented in a given array.\"\\n\\n\\n\"The maximum...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>False</td>\n",
       "      <td>6</td>\n",
       "      <td>maximum:</td>\n",
       "      <td>maximum:\\n\\n* Required Field * Name of the User (required) Email Address (required) Password (required) * Required F...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>False</td>\n",
       "      <td>6</td>\n",
       "      <td>maximum:</td>\n",
       "      <td>maximum: 100;\\n\\nmax-width: 200px;\\n\\nmax-height: 300px;\\n\\n\\n}\\n\\n\\n.side .md h1 { font-size: 18px; }\\n\\n\\n.side .m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>False</td>\n",
       "      <td>6</td>\n",
       "      <td>maximum:</td>\n",
       "      <td>maximum:\\n\\n- 1.5 million players (in the game)\\n\\n- 1.5 million players (in the game) Maximum play time: 2 hours, 3...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>True</td>\n",
       "      <td>6</td>\n",
       "      <td>maximum:</td>\n",
       "      <td>maximum: The maximum number of items that can be added to a single list.\\n\\nmax-list: The maximum number of items th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>True</td>\n",
       "      <td>6</td>\n",
       "      <td>maximum:</td>\n",
       "      <td>maximum:\\n\\n\"The maximum number of items that can be in a single list. This is used to avoid recursion when creating...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>True</td>\n",
       "      <td>6</td>\n",
       "      <td>maximum:</td>\n",
       "      <td>maximum:\\n\\nCALLING ALL BIKES!\\n\\nA FREE FESTIVAL OF RIDING &amp; TAKING IN THE CITY!\\n\\n\\nTHE FESTIVAL IS SOLD OUT, BUT...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>True</td>\n",
       "      <td>6</td>\n",
       "      <td>maximum:</td>\n",
       "      <td>maximum: 100\\n\\nmax_size: 0.1\\n\\nuse_transparent: 1\\n\\n\\nI have created a python script that can be used to calculat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>True</td>\n",
       "      <td>6</td>\n",
       "      <td>maximum:</td>\n",
       "      <td>maximum: The maximum number of values that can be stored in a variable.\\n\\nmin: The minimum number of values that ca...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>True</td>\n",
       "      <td>12</td>\n",
       "      <td>maximum:</td>\n",
       "      <td>maximum: The maximum number of items that can be added to a single request.\\n\\nmax_request_size: The maximum size of...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>True</td>\n",
       "      <td>12</td>\n",
       "      <td>maximum:</td>\n",
       "      <td>maximum:\\n\\n\"The maximum number of consecutive integers that can be represented in a given array type. This is the m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>True</td>\n",
       "      <td>12</td>\n",
       "      <td>maximum:</td>\n",
       "      <td>maximum:\\n\\n*Please note that the maximum amount of money you can donate is $5,000.00 USD.\\n\\nWe will be using the f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>True</td>\n",
       "      <td>12</td>\n",
       "      <td>maximum:</td>\n",
       "      <td>maximum: 0.5\\n\\n0.5 min/max: 0.2\\n\\n0.2 min/max: 0.1\\n\\n\\nThe speed of the particles is proportional to the square r...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>True</td>\n",
       "      <td>12</td>\n",
       "      <td>maximum:</td>\n",
       "      <td>maximum:\\n\\nThe maximum number of times a player can be hit by the same attack.\\n\\nA character's maximum HP is deter...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>True</td>\n",
       "      <td>24</td>\n",
       "      <td>maximum:</td>\n",
       "      <td>maximum: (a) the maximum length of a human life; or (b) the maximum number of days in a year.\\n\\n(2) The following d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>True</td>\n",
       "      <td>24</td>\n",
       "      <td>maximum:</td>\n",
       "      <td>maximum:\\n\\n\"The maximum number of consecutive integers that can be represented in a given array.\"\\n\\n\\n\"The maximum...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>True</td>\n",
       "      <td>24</td>\n",
       "      <td>maximum:</td>\n",
       "      <td>maximum:\\n\\n* If you are using the first time installation of your device, please check that the version of Android ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>True</td>\n",
       "      <td>24</td>\n",
       "      <td>maximum:</td>\n",
       "      <td>maximum:: 10;\\n\\nmin: 0;\\n\\nmax_rows: 10;\\n\\nmax_cols: 10;\\n\\n\\n// If the number of rows is less than max_rows, it w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>True</td>\n",
       "      <td>24</td>\n",
       "      <td>maximum:</td>\n",
       "      <td>maximum:\\n\\n- 1.5 - 2.0 inches (4 - 6 cm)\\n\\n- 2.0 inches (5 cm) maximum diameter of a circular needle, or size need...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>True</td>\n",
       "      <td>36</td>\n",
       "      <td>maximum:</td>\n",
       "      <td>maximum:: 4.0;\\n\\n}\\n\\n\\n@media only screen and (max-width: 600px) {\\n\\n.h2 {\\n\\nfont-size: 1.5em; font-weight: bold...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>True</td>\n",
       "      <td>36</td>\n",
       "      <td>maximum:</td>\n",
       "      <td>maximum:\\n\\n\"The maximum number of consecutive integers that can be represented in a given array.\"\\n\\n\\n\"The maximum...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>True</td>\n",
       "      <td>36</td>\n",
       "      <td>maximum:</td>\n",
       "      <td>maximum:\\n\\n* If the maximum value is not specified, it will be used as the minimum.\\n\\n* If the maximum value is no...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>True</td>\n",
       "      <td>36</td>\n",
       "      <td>maximum:</td>\n",
       "      <td>maximum:: 10;\\n\\nmin: 0;\\n\\nmax_rows: 10;\\n\\nmax_cols: 10;\\n\\n\\n// If the number of rows is less than max_rows, it w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>True</td>\n",
       "      <td>36</td>\n",
       "      <td>maximum:</td>\n",
       "      <td>maximum:\\n\\n- 1.5 million players (in the game)\\n\\n- 1.5 million players (in the game) Maximum play time: 2 hours, 3...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    steered  layer     input  \\\n",
       "0     False      6  maximum:   \n",
       "1     False      6  maximum:   \n",
       "2     False      6  maximum:   \n",
       "3     False      6  maximum:   \n",
       "4     False      6  maximum:   \n",
       "5      True      6  maximum:   \n",
       "6      True      6  maximum:   \n",
       "7      True      6  maximum:   \n",
       "8      True      6  maximum:   \n",
       "9      True      6  maximum:   \n",
       "10     True     12  maximum:   \n",
       "11     True     12  maximum:   \n",
       "12     True     12  maximum:   \n",
       "13     True     12  maximum:   \n",
       "14     True     12  maximum:   \n",
       "15     True     24  maximum:   \n",
       "16     True     24  maximum:   \n",
       "17     True     24  maximum:   \n",
       "18     True     24  maximum:   \n",
       "19     True     24  maximum:   \n",
       "20     True     36  maximum:   \n",
       "21     True     36  maximum:   \n",
       "22     True     36  maximum:   \n",
       "23     True     36  maximum:   \n",
       "24     True     36  maximum:   \n",
       "\n",
       "                                                                                                                     output  \n",
       "0   maximum: 0.0; minimum: 0.0; step: 1.0\\n\\nThe maximum and minimum values are in decimal notation, and the step is in ...  \n",
       "1   maximum:\\n\\n\"The maximum number of consecutive integers that can be represented in a given array.\"\\n\\n\\n\"The maximum...  \n",
       "2   maximum:\\n\\n* Required Field * Name of the User (required) Email Address (required) Password (required) * Required F...  \n",
       "3   maximum: 100;\\n\\nmax-width: 200px;\\n\\nmax-height: 300px;\\n\\n\\n}\\n\\n\\n.side .md h1 { font-size: 18px; }\\n\\n\\n.side .m...  \n",
       "4   maximum:\\n\\n- 1.5 million players (in the game)\\n\\n- 1.5 million players (in the game) Maximum play time: 2 hours, 3...  \n",
       "5   maximum: The maximum number of items that can be added to a single list.\\n\\nmax-list: The maximum number of items th...  \n",
       "6   maximum:\\n\\n\"The maximum number of items that can be in a single list. This is used to avoid recursion when creating...  \n",
       "7   maximum:\\n\\nCALLING ALL BIKES!\\n\\nA FREE FESTIVAL OF RIDING & TAKING IN THE CITY!\\n\\n\\nTHE FESTIVAL IS SOLD OUT, BUT...  \n",
       "8   maximum: 100\\n\\nmax_size: 0.1\\n\\nuse_transparent: 1\\n\\n\\nI have created a python script that can be used to calculat...  \n",
       "9   maximum: The maximum number of values that can be stored in a variable.\\n\\nmin: The minimum number of values that ca...  \n",
       "10  maximum: The maximum number of items that can be added to a single request.\\n\\nmax_request_size: The maximum size of...  \n",
       "11  maximum:\\n\\n\"The maximum number of consecutive integers that can be represented in a given array type. This is the m...  \n",
       "12  maximum:\\n\\n*Please note that the maximum amount of money you can donate is $5,000.00 USD.\\n\\nWe will be using the f...  \n",
       "13  maximum: 0.5\\n\\n0.5 min/max: 0.2\\n\\n0.2 min/max: 0.1\\n\\n\\nThe speed of the particles is proportional to the square r...  \n",
       "14  maximum:\\n\\nThe maximum number of times a player can be hit by the same attack.\\n\\nA character's maximum HP is deter...  \n",
       "15  maximum: (a) the maximum length of a human life; or (b) the maximum number of days in a year.\\n\\n(2) The following d...  \n",
       "16  maximum:\\n\\n\"The maximum number of consecutive integers that can be represented in a given array.\"\\n\\n\\n\"The maximum...  \n",
       "17  maximum:\\n\\n* If you are using the first time installation of your device, please check that the version of Android ...  \n",
       "18  maximum:: 10;\\n\\nmin: 0;\\n\\nmax_rows: 10;\\n\\nmax_cols: 10;\\n\\n\\n// If the number of rows is less than max_rows, it w...  \n",
       "19  maximum:\\n\\n- 1.5 - 2.0 inches (4 - 6 cm)\\n\\n- 2.0 inches (5 cm) maximum diameter of a circular needle, or size need...  \n",
       "20  maximum:: 4.0;\\n\\n}\\n\\n\\n@media only screen and (max-width: 600px) {\\n\\n.h2 {\\n\\nfont-size: 1.5em; font-weight: bold...  \n",
       "21  maximum:\\n\\n\"The maximum number of consecutive integers that can be represented in a given array.\"\\n\\n\\n\"The maximum...  \n",
       "22  maximum:\\n\\n* If the maximum value is not specified, it will be used as the minimum.\\n\\n* If the maximum value is no...  \n",
       "23  maximum:: 10;\\n\\nmin: 0;\\n\\nmax_rows: 10;\\n\\nmax_cols: 10;\\n\\n\\n// If the number of rows is less than max_rows, it w...  \n",
       "24  maximum:\\n\\n- 1.5 million players (in the game)\\n\\n- 1.5 million players (in the game) Maximum play time: 2 hours, 3...  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# display results\n",
    "pd.set_option('display.max_colwidth', 120)\n",
    "pd.DataFrame(results)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
